{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65a8b1bd-c949-4e00-819d-1c7fe8f42082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio\n",
    "import torchaudio.functional as torchaudio_F\n",
    "import torchaudio.transforms as torchaudio_T\n",
    "from torchaudio.backend.soundfile_backend import load\n",
    "import tqdm\n",
    "\n",
    "from src.dataset_v2 import *\n",
    "from src.model import CPC, CPC_classifier_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926e41cb-2ff3-433e-9975-e4bba49bdddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('x', 29998), ('sd', 19364), ('b', 10028), ('sv', 7428), ('+', 4919), ('%', 4294), ('aa', 3014), ('ba', 1112), ('qy', 1043), ('ny', 729)]\n"
     ]
    }
   ],
   "source": [
    "wav_path = os.path.join(os.path.expanduser('~'), 'Jupyter-data/Switchboard-DA')\n",
    "trainset_path = './train.csv'\n",
    "testset_path = './test.csv'\n",
    "df_train, top_labels = build_dataset(wav_path, trainset_path, numeric_only=False)\n",
    "df_test, _ = build_dataset(wav_path, testset_path, top_labels=top_labels, numeric_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5de63-700a-44b3-ba9b-679746001262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5dc999e-8f5b-4de7-af4d-0b7d88aaec24",
   "metadata": {},
   "source": [
    "## Get CPC embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a6b3a-ad5a-4f80-be6f-6d892651d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CPC(decoder_heads=12)\n",
    "model.load_state_dict(torch.load('./libri-182794-fw3-h12-ep4.pth'))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c54a6fb-5f53-4a77-940d-2c1ac0258d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15139\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "df_target_dataset = df_test\n",
    "\n",
    "dataset = Switchboard_Dataset_v1(df_target_dataset)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=padding_tensor_extractor_v1)\n",
    "print(dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5152cc95-51a8-4131-88db-54eec9005bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 947/947 [00:31<00:00, 30.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get CPC embedding\n",
    "model.eval()\n",
    "\n",
    "c_t_collect = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, x_len in tqdm.tqdm(dataloader):\n",
    "        phi_n, c_n = model(x.to('cuda'))\n",
    "\n",
    "        t = (x_len/8000*100).astype(int) - 1\n",
    "        c_t = torch.zeros((x.shape[0], model.c_dim))\n",
    "        for i in range(x.shape[0]):\n",
    "            c_t[i] = c_n[i,t[i],:].cpu()\n",
    "    \n",
    "        c_t_collect.append(c_t)\n",
    "\n",
    "tensot_c_t = torch.concat(c_t_collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d49ca4bd-8d3f-4f68-9455-c3dbea3cc9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted_feature = df_target_dataset[['dialog_id', 'speaker', 'da_tag', 'start_time', 'end_time', 'label']]\n",
    "df_extracted_feature = pd.concat([df_extracted_feature, pd.DataFrame(tensot_c_t.numpy())], axis=1)\n",
    "df_extracted_feature.to_csv('./feature_cpc_182794_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393af1fb-d5c9-4c7f-8864-cf939a8cb9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77a9989-9b84-497c-8e71-25bd5b15c6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "497630f0-8951-4967-92cb-0bbdaab7e6e7",
   "metadata": {},
   "source": [
    "## Get CLF embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b334f0e0-579d-4b31-a4c3-0d84d29a96aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "model_clf = CPC_classifier_v3(\n",
    "    phi_dim=256,\n",
    "    c_dim=128,\n",
    "    rnn_num_layers=1,\n",
    ")\n",
    "model_clf.load_state_dict(torch.load('./sw-clfv3-vF-step160k.pth'))\n",
    "model_clf.cuda()\n",
    "model_clf.eval()\n",
    "print('ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d11f5596-16d9-4a00-ba9d-f3ef366112ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLF_Head_no_softmax(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CLF_Head_no_softmax(nn.Module):\n",
    "    def __init__(self, input_dim=128, output_dim=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mlp = nn.Sequential( # downsampling factor = 160\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "      \n",
    "    def forward(self, x):\n",
    "        out = self.mlp(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "decoder = CLF_Head_no_softmax()\n",
    "\n",
    "# copy decoder params and buffer\n",
    "params_clf = model_clf.named_parameters()\n",
    "buffer_clf = model_clf.named_buffers()\n",
    "params_decoder = decoder.named_parameters()\n",
    "buffer_decoder = decoder.named_buffers()\n",
    "\n",
    "state_dict_decoder = {**dict(params_decoder), **dict(buffer_decoder)}\n",
    "\n",
    "for name, param in params_clf:\n",
    "    if name in state_dict_decoder:\n",
    "        state_dict_decoder[name].data.copy_(param.data)\n",
    "        \n",
    "for name, param in buffer_clf:\n",
    "    if name in state_dict_decoder:\n",
    "        state_dict_decoder[name].data.copy_(param.data)\n",
    "        \n",
    "decoder.load_state_dict(state_dict_decoder)\n",
    "decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f1929b4-8175-4ed2-a7ab-ab8e95b4bf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15139\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "# df_target_dataset = df_train\n",
    "df_target_dataset = df_test\n",
    "\n",
    "dataset = Switchboard_Dataset_trainer_v3(df_target_dataset)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=padding_tensor_trainer_v3)\n",
    "\n",
    "print(dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4011c6b0-39b7-459e-84f5-dfa656dfc93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 474/474 [00:35<00:00, 13.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get clf result\n",
    "c_t_collect = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm.tqdm(dataloader):\n",
    "        phi_n = model_clf.encoder(x[:,0:1,:].to('cuda'))\n",
    "        ind_n = model_clf.encoder2(x[:,1:2,:].to('cuda'))\n",
    "        phi_cat = torch.concat((phi_n,ind_n),1)\n",
    "\n",
    "        c_n, h_n = model_clf.auto_regressive(torch.permute(phi_cat, (0, 2, 1)))\n",
    "        embed = decoder(h_n[0])\n",
    "    \n",
    "        c_t_collect.append(embed.cpu())\n",
    "\n",
    "tensot_c_t = torch.concat(c_t_collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4da2ccfa-c73a-4d54-817a-fac7c65de078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted_feature = df_target_dataset[['dialog_id', 'speaker', 'da_tag', 'start_time', 'end_time', 'label']]\n",
    "df_extracted_feature = pd.concat([df_extracted_feature, pd.DataFrame(tensot_c_t.numpy())], axis=1)\n",
    "df_extracted_feature.to_csv('./feature_clfvF_160k_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
